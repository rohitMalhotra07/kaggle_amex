{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae8d49c-196a-4121-aae9-a27963647d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54928f1c-2c1e-4cc6-9351-99465251f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from models.models_new import AttentionModel,GRUModel,GRUModel2,AttentionModelConv1d\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e3cf93-10ba-4775-a16f-b35a87d3aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.np_loader import NumpyDataDatasetInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11cddf66-6c9f-4a0e-a547-eb197b8131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2141f9d-aba4-4855-8f16-93b926d69adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainerInference(pl.LightningModule):\n",
    "    def __init__(self, cfg, num_workers = 15):\n",
    "        super().__init__()\n",
    "        \n",
    "        # self.model = AttentionModel(cfg.embed_dim, cfg.feat_dim, cfg.num_heads, cfg.ff_dim, cfg.dropout_rate, cfg.num_blocks)\n",
    "        # self.model = GRUModel2(cfg.embed_dim, cfg.feat_dim, cfg.dropout_rate, cfg.num_layers_rnn)\n",
    "        self.model = AttentionModelConv1d(cfg.embed_dim, cfg.feat_dim, cfg.num_heads, cfg.ff_dim, cfg.dropout_rate, cfg.num_blocks)\n",
    "        \n",
    "        self.batch_size = cfg.batch_size\n",
    "        \n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "\n",
    "    def forward(self, x_cont):\n",
    "        return self.model(x_cont)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb18e17-c591-4436-a0f3-f288fdad3885",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(X_p, model):\n",
    "    p_dataset = NumpyDataDatasetInference(X_p)\n",
    "    p_loader = DataLoader(dataset=p_dataset, batch_size=512, shuffle=False, num_workers=15)\n",
    "    preds = []\n",
    "    for step, x in enumerate(p_loader):\n",
    "        y_hat = model(x).tolist()\n",
    "        preds.extend(y_hat)\n",
    "    return np.array(preds)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e38e4b9-c840-41d1-9a70-4c277341bcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferring Test_File_1\n",
      "Inferring Test_File_2\n",
      "Inferring Test_File_3\n",
      "Inferring Test_File_4\n",
      "Inferring Test_File_5\n",
      "Inferring Test_File_6\n",
      "Inferring Test_File_7\n",
      "Inferring Test_File_8\n",
      "Inferring Test_File_9\n",
      "Inferring Test_File_10\n",
      "Inferring Test_File_11\n",
      "Inferring Test_File_12\n",
      "Inferring Test_File_13\n",
      "Inferring Test_File_14\n",
      "Inferring Test_File_15\n",
      "Inferring Test_File_16\n",
      "Inferring Test_File_17\n",
      "Inferring Test_File_18\n",
      "Inferring Test_File_19\n",
      "Inferring Test_File_20\n"
     ]
    }
   ],
   "source": [
    "start = 0; end = 0\n",
    "sub = pd.read_csv(f'{cfg.data_dir}sample_submission.csv')\n",
    "\n",
    "# REARANGE SUB ROWS TO MATCH 20 TEST FILES\n",
    "# sub['hash'] = sub['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n",
    "sub['hash'] = sub['customer_ID'].str[-16:].apply(lambda x: int(x, 16)).astype('int64')\n",
    "test_hash_index = np.load(f'{cfg.prc_data_dir}test_hashes_data.npy')\n",
    "sub = sub.set_index('hash').loc[test_hash_index].reset_index(drop=True)\n",
    "\n",
    "for k in range(20):\n",
    "    print(f'Inferring Test_File_{k+1}')\n",
    "    X_test = np.load(f'{cfg.prc_data_dir}test_data_{k+1}.npy')\n",
    "    end = start + X_test.shape[0]\n",
    "\n",
    "    # INFER 5 FOLD MODELS f\"multihead_attention_{fold}\"\n",
    "    # print(f'checkpoints/{cfg.model_name}_{0}_{cfg.version}.ckpt')\n",
    "    model = ModelTrainerInference.load_from_checkpoint(f'checkpoints/{cfg.model_name}_{0}_{cfg.version}.ckpt', cfg=cfg)\n",
    "    model.eval()\n",
    "    p = predict_data(X_test, model)\n",
    "    \n",
    "    for j in range(1,5):\n",
    "        model = ModelTrainerInference.load_from_checkpoint(f'checkpoints/{cfg.model_name}_{j}_{cfg.version}.ckpt', cfg=cfg)\n",
    "        model.eval()\n",
    "        p += predict_data(X_test, model)\n",
    "    p /= 5.0\n",
    "\n",
    "    sub.loc[start:end-1,'prediction'] = p\n",
    "    start = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70fd451e-9458-4b8d-9a2b-355fdea5d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file shape is (924621, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>038be0571bd6b3776cb8512731968f4de302c811030124...</td>\n",
       "      <td>0.002081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0074a0233ef766b52884608cc8cf9098f59d885b5d59fc...</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>060b8b7f30f795a0e93995d45b29461ffa6ece0eeb5c3d...</td>\n",
       "      <td>0.120746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03a1d125bdd776000bf0b28238d0bea240ad581d332e70...</td>\n",
       "      <td>0.178329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0290f245dd35ba899af52316ccc62b2627e7ae18cd76a2...</td>\n",
       "      <td>0.431587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  prediction\n",
       "0  038be0571bd6b3776cb8512731968f4de302c811030124...    0.002081\n",
       "1  0074a0233ef766b52884608cc8cf9098f59d885b5d59fc...    0.000434\n",
       "2  060b8b7f30f795a0e93995d45b29461ffa6ece0eeb5c3d...    0.120746\n",
       "3  03a1d125bdd776000bf0b28238d0bea240ad581d332e70...    0.178329\n",
       "4  0290f245dd35ba899af52316ccc62b2627e7ae18cd76a2...    0.431587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub.to_csv(f'{cfg.model_name}_{cfg.version}_submission.csv',index=False)\n",
    "print('Submission file shape is', sub.shape )\n",
    "display( sub.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485cff76-a0d0-4522-967c-9edf9d77221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3de29048-79ee-4ea2-abb2-2ecb1bea77c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.rand(2,13,188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbabf76d-ee60-4d8d-a9d0-f04981e7f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = nn.Conv1d(13, 7, kernel_size=3, stride=2, padding=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cab8e6b-f5b5-4102-a0fc-2508c2a78d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1 = m1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edf47e8-f155-4c1d-9f8d-2f09b57f5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# o1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb19a9f7-f606-4c4a-a9c2-aae01d3b60bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
